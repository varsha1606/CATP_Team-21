{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5369083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word or a sentence: good\n",
      "How many words do you want to predict? 10\n",
      "Predicted next words: ['quite', 'enough', 'news', 'deal', 'lose', 'oh', 'bowed', 'look', 'wilson', 'worker']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "import json\n",
    "\n",
    "# Function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Function to create n-grams\n",
    "def create_ngrams(tokens, n):\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [' '.join(gram) for gram in n_grams]\n",
    "\n",
    "# Load and preprocess the text file\n",
    "def load_and_preprocess(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    tokens = preprocess_text(text)\n",
    "    return tokens\n",
    "\n",
    "# Predict the next words based on the input sentence\n",
    "def predict_next_words(tokens, input_sentence, num_words):\n",
    "    input_tokens = preprocess_text(input_sentence)\n",
    "    input_tokens_length = len(input_tokens)\n",
    "    predicted_words = []\n",
    "    predicted_set = set()\n",
    "    \n",
    "    # Look for potential continuations of the input sentence\n",
    "    for i in range(len(tokens) - input_tokens_length):\n",
    "        overlap = sum([1 for a, b in zip(tokens[i:i + input_tokens_length], input_tokens) if a == b])\n",
    "        if overlap == input_tokens_length:\n",
    "            next_word = tokens[i + input_tokens_length]\n",
    "            if next_word not in predicted_set:\n",
    "                predicted_words.append(next_word)\n",
    "                predicted_set.add(next_word)\n",
    "                if len(predicted_words) == num_words:\n",
    "                    break\n",
    "    \n",
    "    return predicted_words\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and preprocess the text file\n",
    "    file_path = \"C:/Users/varsh/Downloads/Sherlock Holmes.txt\"  # Adjust the file path as needed\n",
    "    tokens = load_and_preprocess(file_path)\n",
    "    \n",
    "    # User input\n",
    "    input_sentence = input(\"Enter a word or a sentence: \")\n",
    "    num_words = int(input(\"How many words do you want to predict? \"))\n",
    "    \n",
    "    # Predict the next words\n",
    "    predicted_words = predict_next_words(tokens, input_sentence, num_words)\n",
    "    \n",
    "    # Check if the number of predicted words is less than the requested number\n",
    "    if len(predicted_words) < num_words:\n",
    "        print(f\"Only {len(predicted_words)} predicted words are available. These are the available words:\")\n",
    "        print(predicted_words)\n",
    "    else:\n",
    "        print(\"Predicted next words:\", predicted_words)\n",
    "    \n",
    "    # Save predictions to a JSON file\n",
    "    with open('ngram_predictions.json', 'w') as f:\n",
    "        json.dump(predicted_words, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19401a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
